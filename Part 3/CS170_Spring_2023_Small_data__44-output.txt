Welcome to Abhinav's, Majd's, Jacqueline's and Rovin's Feature Selection Algorithms.
Type in the name of the file to test: CS170_Spring_2023_Small_data__44.txt
File processed successfully.
Type the number of the algorithm you want to run.
1- Forward Selection.
2- Backward Elimination.
3- Random Combinations.
1

This dataset has 10 features (not including the class attribute), with 100 instances.
Please wait while I normalize the data...

Do you want to Z Normalize the data values? (y/n): y
Done!

Running nearest neighbor with no features (default rate), using “leaving-one-out” evaluation, we get an accuracy of  86.0 %
---------------------------------------------
Beginning search (Forward Feature Selection).
---------------------------------------------
On level  1  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  73.0 %
--Considering adding feature number  2  gets us a total accuracy of  77.0 %
--Considering adding feature number  3  gets us a total accuracy of  88.0 %
--Considering adding feature number  4  gets us a total accuracy of  76.0 %
--Considering adding feature number  5  gets us a total accuracy of  78.0 %
--Considering adding feature number  6  gets us a total accuracy of  79.0 %
--Considering adding feature number  7  gets us a total accuracy of  78.0 %
--Considering adding feature number  8  gets us a total accuracy of  72.0 %
--Considering adding feature number  9  gets us a total accuracy of  75.0 %
--Considering adding feature number  10  gets us a total accuracy of  74.0 %

On level  1  feature { 3 } was added to current set
Current Set of Features:  [3]  with accuracy of  88.0 %
---------------------------------------------
On level  2  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  86.0 %
--Considering adding feature number  2  gets us a total accuracy of  80.0 %
--Considering adding feature number  4  gets us a total accuracy of  85.0 %
--Considering adding feature number  5  gets us a total accuracy of  95.0 %
--Considering adding feature number  6  gets us a total accuracy of  82.0 %
--Considering adding feature number  7  gets us a total accuracy of  90.0 %
--Considering adding feature number  8  gets us a total accuracy of  86.0 %
--Considering adding feature number  9  gets us a total accuracy of  78.0 %
--Considering adding feature number  10  gets us a total accuracy of  88.0 %

On level  2  feature { 5 } was added to current set
Current Set of Features:  [3, 5]  with accuracy of  95.0 %
---------------------------------------------
On level  3  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  87.0 %
--Considering adding feature number  2  gets us a total accuracy of  84.0 %
--Considering adding feature number  4  gets us a total accuracy of  85.0 %
--Considering adding feature number  6  gets us a total accuracy of  86.0 %
--Considering adding feature number  7  gets us a total accuracy of  90.0 %
--Considering adding feature number  8  gets us a total accuracy of  85.0 %
--Considering adding feature number  9  gets us a total accuracy of  78.0 %
--Considering adding feature number  10  gets us a total accuracy of  92.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  3  feature { 10 } was added to current set
Current Set of Features:  [3, 5, 10]  with accuracy of  92.0 %
---------------------------------------------
On level  4  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  88.0 %
--Considering adding feature number  2  gets us a total accuracy of  75.0 %
--Considering adding feature number  4  gets us a total accuracy of  85.0 %
--Considering adding feature number  6  gets us a total accuracy of  79.0 %
--Considering adding feature number  7  gets us a total accuracy of  84.0 %
--Considering adding feature number  8  gets us a total accuracy of  82.0 %
--Considering adding feature number  9  gets us a total accuracy of  89.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  4  feature { 9 } was added to current set
Current Set of Features:  [3, 5, 10, 9]  with accuracy of  89.0 %
---------------------------------------------
On level  5  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  82.0 %
--Considering adding feature number  2  gets us a total accuracy of  83.0 %
--Considering adding feature number  4  gets us a total accuracy of  81.0 %
--Considering adding feature number  6  gets us a total accuracy of  76.0 %
--Considering adding feature number  7  gets us a total accuracy of  84.0 %
--Considering adding feature number  8  gets us a total accuracy of  79.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  5  feature { 7 } was added to current set
Current Set of Features:  [3, 5, 10, 9, 7]  with accuracy of  84.0 %
---------------------------------------------
On level  6  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  79.0 %
--Considering adding feature number  2  gets us a total accuracy of  83.0 %
--Considering adding feature number  4  gets us a total accuracy of  78.0 %
--Considering adding feature number  6  gets us a total accuracy of  73.0 %
--Considering adding feature number  8  gets us a total accuracy of  82.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  6  feature { 2 } was added to current set
Current Set of Features:  [3, 5, 10, 9, 7, 2]  with accuracy of  83.0 %
---------------------------------------------
On level  7  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  83.0 %
--Considering adding feature number  4  gets us a total accuracy of  77.0 %
--Considering adding feature number  6  gets us a total accuracy of  77.0 %
--Considering adding feature number  8  gets us a total accuracy of  74.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  7  feature { 1 } was added to current set
Current Set of Features:  [3, 5, 10, 9, 7, 2, 1]  with accuracy of  83.0 %
---------------------------------------------
On level  8  of the search tree

--Considering adding feature number  4  gets us a total accuracy of  80.0 %
--Considering adding feature number  6  gets us a total accuracy of  75.0 %
--Considering adding feature number  8  gets us a total accuracy of  76.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  8  feature { 4 } was added to current set
Current Set of Features:  [3, 5, 10, 9, 7, 2, 1, 4]  with accuracy of  80.0 %
---------------------------------------------
On level  9  of the search tree

--Considering adding feature number  6  gets us a total accuracy of  77.0 %
--Considering adding feature number  8  gets us a total accuracy of  78.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  9  feature { 8 } was added to current set
Current Set of Features:  [3, 5, 10, 9, 7, 2, 1, 4, 8]  with accuracy of  78.0 %
---------------------------------------------
On level  10  of the search tree

--Considering adding feature number  6  gets us a total accuracy of  73.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  10  feature { 6 } was added to current set
Current Set of Features:  [3, 5, 10, 9, 7, 2, 1, 4, 8, 6]  with accuracy of  73.0 %
---------------------------------------------
Set  [3, 5]  has the highest accuracy: 95.0
Elapsed time: 0.376 seconds

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Welcome to Abhinav's, Majd's, Jacqueline's and Rovin's Feature Selection Algorithms.
Type in the name of the file to test: CS170_Spring_2023_Small_data__44.txt
File processed successfully.
Type the number of the algorithm you want to run.
1- Forward Selection.
2- Backward Elimination.
3- Random Combinations.
2

This dataset has 10 features (not including the class attribute), with 100 instances.
Please wait while I normalize the data...

Do you want to Z Normalize the data values? (y/n): y
Done!

Running nearest neighbor with all the features, using “leaving-one-out” evaluation, we get an accuracy of  73.0 %
---------------------------------------------
Beginning search (Backward Feature Elimination).
---------------------------------------------
On level  10  of the search tree

--Considering removing feature number  10  gets us a total accuracy of  79.0 %
--Considering removing feature number  9  gets us a total accuracy of  74.0 %
--Considering removing feature number  8  gets us a total accuracy of  77.0 %
--Considering removing feature number  7  gets us a total accuracy of  79.0 %
--Considering removing feature number  6  gets us a total accuracy of  78.0 %
--Considering removing feature number  5  gets us a total accuracy of  73.0 %
--Considering removing feature number  4  gets us a total accuracy of  77.0 %
--Considering removing feature number  3  gets us a total accuracy of  72.0 %
--Considering removing feature number  2  gets us a total accuracy of  74.0 %
--Considering removing feature number  1  gets us a total accuracy of  67.0 %

On level  10  feature { 10 } was removed from current set
Current Set of Features:  [1, 2, 3, 4, 5, 6, 7, 8, 9]  with accuracy of  79.0 %
---------------------------------------------
On level  9  of the search tree

--Considering removing feature number  9  gets us a total accuracy of  79.0 %
--Considering removing feature number  8  gets us a total accuracy of  80.0 %
--Considering removing feature number  7  gets us a total accuracy of  81.0 %
--Considering removing feature number  6  gets us a total accuracy of  79.0 %
--Considering removing feature number  5  gets us a total accuracy of  76.0 %
--Considering removing feature number  4  gets us a total accuracy of  82.0 %
--Considering removing feature number  3  gets us a total accuracy of  70.0 %
--Considering removing feature number  2  gets us a total accuracy of  79.0 %
--Considering removing feature number  1  gets us a total accuracy of  72.0 %

On level  9  feature { 4 } was removed from current set
Current Set of Features:  [1, 2, 3, 5, 6, 7, 8, 9]  with accuracy of  82.0 %
---------------------------------------------
On level  8  of the search tree

--Considering removing feature number  9  gets us a total accuracy of  82.0 %
--Considering removing feature number  8  gets us a total accuracy of  82.0 %
--Considering removing feature number  7  gets us a total accuracy of  83.0 %
--Considering removing feature number  6  gets us a total accuracy of  80.0 %
--Considering removing feature number  5  gets us a total accuracy of  81.0 %
--Considering removing feature number  3  gets us a total accuracy of  73.0 %
--Considering removing feature number  2  gets us a total accuracy of  78.0 %
--Considering removing feature number  1  gets us a total accuracy of  78.0 %

On level  8  feature { 7 } was removed from current set
Current Set of Features:  [1, 2, 3, 5, 6, 8, 9]  with accuracy of  83.0 %
---------------------------------------------
On level  7  of the search tree

--Considering removing feature number  9  gets us a total accuracy of  78.0 %
--Considering removing feature number  8  gets us a total accuracy of  86.0 %
--Considering removing feature number  6  gets us a total accuracy of  81.0 %
--Considering removing feature number  5  gets us a total accuracy of  82.0 %
--Considering removing feature number  3  gets us a total accuracy of  77.0 %
--Considering removing feature number  2  gets us a total accuracy of  78.0 %
--Considering removing feature number  1  gets us a total accuracy of  71.0 %

On level  7  feature { 8 } was removed from current set
Current Set of Features:  [1, 2, 3, 5, 6, 9]  with accuracy of  86.0 %
---------------------------------------------
On level  6  of the search tree

--Considering removing feature number  9  gets us a total accuracy of  85.0 %
--Considering removing feature number  6  gets us a total accuracy of  82.0 %
--Considering removing feature number  5  gets us a total accuracy of  82.0 %
--Considering removing feature number  3  gets us a total accuracy of  78.0 %
--Considering removing feature number  2  gets us a total accuracy of  84.0 %
--Considering removing feature number  1  gets us a total accuracy of  73.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  6  feature { 9 } was removed from current set
Current Set of Features:  [1, 2, 3, 5, 6]  with accuracy of  85.0 %
---------------------------------------------
On level  5  of the search tree

--Considering removing feature number  6  gets us a total accuracy of  81.0 %
--Considering removing feature number  5  gets us a total accuracy of  84.0 %
--Considering removing feature number  3  gets us a total accuracy of  76.0 %
--Considering removing feature number  2  gets us a total accuracy of  84.0 %
--Considering removing feature number  1  gets us a total accuracy of  78.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  5  feature { 5 } was removed from current set
Current Set of Features:  [1, 2, 3, 6]  with accuracy of  84.0 %
---------------------------------------------
On level  4  of the search tree

--Considering removing feature number  6  gets us a total accuracy of  80.0 %
--Considering removing feature number  3  gets us a total accuracy of  77.0 %
--Considering removing feature number  2  gets us a total accuracy of  86.0 %
--Considering removing feature number  1  gets us a total accuracy of  80.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  4  feature { 2 } was removed from current set
Current Set of Features:  [1, 3, 6]  with accuracy of  86.0 %
---------------------------------------------
On level  3  of the search tree

--Considering removing feature number  6  gets us a total accuracy of  86.0 %
--Considering removing feature number  3  gets us a total accuracy of  73.0 %
--Considering removing feature number  1  gets us a total accuracy of  82.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  3  feature { 6 } was removed from current set
Current Set of Features:  [1, 3]  with accuracy of  86.0 %
---------------------------------------------
On level  2  of the search tree

--Considering removing feature number  3  gets us a total accuracy of  73.0 %
--Considering removing feature number  1  gets us a total accuracy of  88.0 %

On level  2  feature { 1 } was removed from current set
Current Set of Features:  [3]  with accuracy of  88.0 %
---------------------------------------------
On level  1  of the search tree

--Considering removing feature number  3  gets us a total accuracy of  86.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  1  feature { 3 } was removed from current set
Current Set of Features:  []  with accuracy of  86.0 %
---------------------------------------------
Set  [3]  has the highest accuracy: 88.0
Elapsed time: 0.577 seconds

NOT NORMALIZED
---------------------------------------------
Set  [1, 2, 3, 7]  has the highest accuracy: 90.0
Elapsed time: 0.277 seconds

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Welcome to Abhinav's, Majd's, Jacqueline's and Rovin's Feature Selection Algorithms.
Type in the name of the file to test: CS170_Spring_2023_Small_data__44.txt
File processed successfully.
Type the number of the algorithm you want to run.
1- Forward Selection.
2- Backward Elimination.
3- Random Combinations.
3

This dataset has 10 features (not including the class attribute), with 100 instances.
Please wait while I normalize the data...

Do you want to Z Normalize the data values? (y/n): Y
Done!

Default number of subsets is  10 and number of features in each set is log( 10 )= 3
Do you want to change the default values? (y/n): n

Num of total features:  10  Features number in one set:  3

Features sets:  [(3, 4, 5), (2, 7, 9), (3, 7, 10), (1, 4, 5), (4, 6, 10), (1, 3, 8), (1, 8, 9), (3, 6, 8), (4, 7, 9), (3, 6, 10)]
---------------------------------------------
Beginning search (Random Feature Combinations).
---------------------------------------------
Accuracy for feature set (3, 4, 5) : 85.0
Accuracy for feature set (2, 7, 9) : 74.0
Accuracy for feature set (3, 7, 10) : 82.0
Accuracy for feature set (1, 4, 5) : 81.0
Accuracy for feature set (4, 6, 10) : 70.0
Accuracy for feature set (1, 3, 8) : 86.0
Accuracy for feature set (1, 8, 9) : 71.0
Accuracy for feature set (3, 6, 8) : 75.0
Accuracy for feature set (4, 7, 9) : 75.0
Accuracy for feature set (3, 6, 10) : 78.0

Set  (1, 3, 8)  has the highest accuracy: 86.0
Elapsed time: 0.076 seconds
