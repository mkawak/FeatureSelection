Welcome to Abhinav's, Majd's, Jacqueline's and Rovin's Feature Selection Algorithms.
Type in the name of the file to test: small-test-dataset.txt
File processed successfully.
Type the number of the algorithm you want to run.
1- Forward Selection.
2- Backward Elimination.
3- Random Combinations.
1

This dataset has 10 features (not including the class attribute), with 100 instances.
Please wait while I normalize the data...
Do you want to Z Normalize the data values? (y/n): Y
Done!

Running nearest neighbor with no features (default rate), using “leaving-one-out” evaluation, we get an accuracy of  75.0 %
---------------------------------------------
Beginning search (Forward Feature Selection).
---------------------------------------------
On level  1  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  56.99999999999999 %
--Considering adding feature number  2  gets us a total accuracy of  54.0 %
--Considering adding feature number  3  gets us a total accuracy of  68.0 %
--Considering adding feature number  4  gets us a total accuracy of  65.0 %
--Considering adding feature number  5  gets us a total accuracy of  75.0 %
--Considering adding feature number  6  gets us a total accuracy of  61.0 %
--Considering adding feature number  7  gets us a total accuracy of  62.0 %
--Considering adding feature number  8  gets us a total accuracy of  60.0 %
--Considering adding feature number  9  gets us a total accuracy of  66.0 %
--Considering adding feature number  10  gets us a total accuracy of  64.0 %

On level  1  feature { 5 } was added to current set
Current Set of Features:  [5]  with accuracy of  75.0 %
---------------------------------------------
On level  2  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  76.0 %
--Considering adding feature number  2  gets us a total accuracy of  80.0 %
--Considering adding feature number  3  gets us a total accuracy of  92.0 %
--Considering adding feature number  4  gets us a total accuracy of  75.0 %
--Considering adding feature number  6  gets us a total accuracy of  79.0 %
--Considering adding feature number  7  gets us a total accuracy of  80.0 %
--Considering adding feature number  8  gets us a total accuracy of  77.0 %
--Considering adding feature number  9  gets us a total accuracy of  73.0 %
--Considering adding feature number  10  gets us a total accuracy of  82.0 %

On level  2  feature { 3 } was added to current set
Current Set of Features:  [5, 3]  with accuracy of  92.0 %
---------------------------------------------
On level  3  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  83.0 %
--Considering adding feature number  2  gets us a total accuracy of  79.0 %
--Considering adding feature number  4  gets us a total accuracy of  84.0 %
--Considering adding feature number  6  gets us a total accuracy of  82.0 %
--Considering adding feature number  7  gets us a total accuracy of  89.0 %
--Considering adding feature number  8  gets us a total accuracy of  79.0 %
--Considering adding feature number  9  gets us a total accuracy of  82.0 %
--Considering adding feature number  10  gets us a total accuracy of  85.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  3  feature { 7 } was added to current set
Current Set of Features:  [5, 3, 7]  with accuracy of  89.0 %
---------------------------------------------
On level  4  of the search tree

--Considering adding feature number  1  gets us a total accuracy of  88.0 %
--Considering adding feature number  2  gets us a total accuracy of  81.0 %
--Considering adding feature number  4  gets us a total accuracy of  78.0 %
--Considering adding feature number  6  gets us a total accuracy of  88.0 %
--Considering adding feature number  8  gets us a total accuracy of  80.0 %
--Considering adding feature number  9  gets us a total accuracy of  82.0 %
--Considering adding feature number  10  gets us a total accuracy of  84.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  4  feature { 1 } was added to current set
Current Set of Features:  [5, 3, 7, 1]  with accuracy of  88.0 %
---------------------------------------------
On level  5  of the search tree

--Considering adding feature number  2  gets us a total accuracy of  79.0 %
--Considering adding feature number  4  gets us a total accuracy of  77.0 %
--Considering adding feature number  6  gets us a total accuracy of  86.0 %
--Considering adding feature number  8  gets us a total accuracy of  75.0 %
--Considering adding feature number  9  gets us a total accuracy of  75.0 %
--Considering adding feature number  10  gets us a total accuracy of  75.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  5  feature { 6 } was added to current set
Current Set of Features:  [5, 3, 7, 1, 6]  with accuracy of  86.0 %
---------------------------------------------
On level  6  of the search tree

--Considering adding feature number  2  gets us a total accuracy of  76.0 %
--Considering adding feature number  4  gets us a total accuracy of  73.0 %
--Considering adding feature number  8  gets us a total accuracy of  78.0 %
--Considering adding feature number  9  gets us a total accuracy of  71.0 %
--Considering adding feature number  10  gets us a total accuracy of  71.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  6  feature { 8 } was added to current set
Current Set of Features:  [5, 3, 7, 1, 6, 8]  with accuracy of  78.0 %
---------------------------------------------
On level  7  of the search tree

--Considering adding feature number  2  gets us a total accuracy of  68.0 %
--Considering adding feature number  4  gets us a total accuracy of  68.0 %
--Considering adding feature number  9  gets us a total accuracy of  72.0 %
--Considering adding feature number  10  gets us a total accuracy of  67.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  7  feature { 9 } was added to current set
Current Set of Features:  [5, 3, 7, 1, 6, 8, 9]  with accuracy of  72.0 %
---------------------------------------------
On level  8  of the search tree

--Considering adding feature number  2  gets us a total accuracy of  70.0 %
--Considering adding feature number  4  gets us a total accuracy of  64.0 %
--Considering adding feature number  10  gets us a total accuracy of  67.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  8  feature { 2 } was added to current set
Current Set of Features:  [5, 3, 7, 1, 6, 8, 9, 2]  with accuracy of  70.0 %
---------------------------------------------
On level  9  of the search tree

--Considering adding feature number  4  gets us a total accuracy of  70.0 %
--Considering adding feature number  10  gets us a total accuracy of  68.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  9  feature { 4 } was added to current set
Current Set of Features:  [5, 3, 7, 1, 6, 8, 9, 2, 4]  with accuracy of  70.0 %
---------------------------------------------
On level  10  of the search tree

--Considering adding feature number  10  gets us a total accuracy of  65.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  10  feature { 10 } was added to current set
Current Set of Features:  [5, 3, 7, 1, 6, 8, 9, 2, 4, 10]  with accuracy of  65.0 %
---------------------------------------------
Set  [5, 3]  has the highest accuracy: 92.0
Elapsed time: 0.39 seconds

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Welcome to Abhinav's, Majd's, Jacqueline's and Rovin's Feature Selection Algorithms.
Type in the name of the file to test: small-test-dataset.txt
File processed successfully.
Type the number of the algorithm you want to run.
1- Forward Selection.
2- Backward Elimination.
3- Random Combinations.
2

This dataset has 10 features (not including the class attribute), with 100 instances.
Please wait while I normalize the data...

Do you want to Z Normalize the data values? (y/n): Y
Done!

Running nearest neighbor with all the features, using “leaving-one-out” evaluation, we get an accuracy of  65.0 %
---------------------------------------------
Beginning search (Backward Feature Elimination).
---------------------------------------------
On level  10  of the search tree

--Considering removing feature number  10  gets us a total accuracy of  70.0 %
--Considering removing feature number  9  gets us a total accuracy of  67.0 %
--Considering removing feature number  8  gets us a total accuracy of  70.0 %
--Considering removing feature number  7  gets us a total accuracy of  61.0 %
--Considering removing feature number  6  gets us a total accuracy of  69.0 %
--Considering removing feature number  5  gets us a total accuracy of  71.0 %
--Considering removing feature number  4  gets us a total accuracy of  68.0 %
--Considering removing feature number  3  gets us a total accuracy of  75.0 %
--Considering removing feature number  2  gets us a total accuracy of  66.0 %
--Considering removing feature number  1  gets us a total accuracy of  69.0 %

On level  10  feature { 3 } was removed from current set
Current Set of Features:  [1, 2, 4, 5, 6, 7, 8, 9, 10]  with accuracy of  75.0 %
---------------------------------------------
On level  9  of the search tree

--Considering removing feature number  10  gets us a total accuracy of  68.0 %
--Considering removing feature number  9  gets us a total accuracy of  74.0 %
--Considering removing feature number  8  gets us a total accuracy of  70.0 %
--Considering removing feature number  7  gets us a total accuracy of  65.0 %
--Considering removing feature number  6  gets us a total accuracy of  77.0 %
--Considering removing feature number  5  gets us a total accuracy of  64.0 %
--Considering removing feature number  4  gets us a total accuracy of  71.0 %
--Considering removing feature number  2  gets us a total accuracy of  74.0 %
--Considering removing feature number  1  gets us a total accuracy of  73.0 %

On level  9  feature { 6 } was removed from current set
Current Set of Features:  [1, 2, 4, 5, 7, 8, 9, 10]  with accuracy of  77.0 %
---------------------------------------------
On level  8  of the search tree

--Considering removing feature number  10  gets us a total accuracy of  71.0 %
--Considering removing feature number  9  gets us a total accuracy of  74.0 %
--Considering removing feature number  8  gets us a total accuracy of  78.0 %
--Considering removing feature number  7  gets us a total accuracy of  69.0 %
--Considering removing feature number  5  gets us a total accuracy of  59.0 %
--Considering removing feature number  4  gets us a total accuracy of  63.0 %
--Considering removing feature number  2  gets us a total accuracy of  74.0 %
--Considering removing feature number  1  gets us a total accuracy of  77.0 %

On level  8  feature { 8 } was removed from current set
Current Set of Features:  [1, 2, 4, 5, 7, 9, 10]  with accuracy of  78.0 %
---------------------------------------------
On level  7  of the search tree

--Considering removing feature number  10  gets us a total accuracy of  75.0 %
--Considering removing feature number  9  gets us a total accuracy of  80.0 %
--Considering removing feature number  7  gets us a total accuracy of  74.0 %
--Considering removing feature number  5  gets us a total accuracy of  65.0 %
--Considering removing feature number  4  gets us a total accuracy of  68.0 %
--Considering removing feature number  2  gets us a total accuracy of  74.0 %
--Considering removing feature number  1  gets us a total accuracy of  76.0 %

On level  7  feature { 9 } was removed from current set
Current Set of Features:  [1, 2, 4, 5, 7, 10]  with accuracy of  80.0 %
---------------------------------------------
On level  6  of the search tree

--Considering removing feature number  10  gets us a total accuracy of  77.0 %
--Considering removing feature number  7  gets us a total accuracy of  72.0 %
--Considering removing feature number  5  gets us a total accuracy of  61.0 %
--Considering removing feature number  4  gets us a total accuracy of  73.0 %
--Considering removing feature number  2  gets us a total accuracy of  72.0 %
--Considering removing feature number  1  gets us a total accuracy of  82.0 %

On level  6  feature { 1 } was removed from current set
Current Set of Features:  [2, 4, 5, 7, 10]  with accuracy of  82.0 %
---------------------------------------------
On level  5  of the search tree

--Considering removing feature number  10  gets us a total accuracy of  77.0 %
--Considering removing feature number  7  gets us a total accuracy of  75.0 %
--Considering removing feature number  5  gets us a total accuracy of  71.0 %
--Considering removing feature number  4  gets us a total accuracy of  79.0 %
--Considering removing feature number  2  gets us a total accuracy of  78.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  5  feature { 4 } was removed from current set
Current Set of Features:  [2, 5, 7, 10]  with accuracy of  79.0 %
---------------------------------------------
On level  4  of the search tree

--Considering removing feature number  10  gets us a total accuracy of  77.0 %
--Considering removing feature number  7  gets us a total accuracy of  72.0 %
--Considering removing feature number  5  gets us a total accuracy of  67.0 %
--Considering removing feature number  2  gets us a total accuracy of  74.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  4  feature { 10 } was removed from current set
Current Set of Features:  [2, 5, 7]  with accuracy of  77.0 %
---------------------------------------------
On level  3  of the search tree

--Considering removing feature number  7  gets us a total accuracy of  80.0 %
--Considering removing feature number  5  gets us a total accuracy of  55.00000000000001 %
--Considering removing feature number  2  gets us a total accuracy of  80.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  3  feature { 7 } was removed from current set
Current Set of Features:  [2, 5]  with accuracy of  80.0 %
---------------------------------------------
On level  2  of the search tree

--Considering removing feature number  5  gets us a total accuracy of  54.0 %
--Considering removing feature number  2  gets us a total accuracy of  75.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  2  feature { 2 } was removed from current set
Current Set of Features:  [5]  with accuracy of  75.0 %
---------------------------------------------
On level  1  of the search tree

--Considering removing feature number  5  gets us a total accuracy of  75.0 %

**Warning, Accuracy has decreased! Continuing search in case of local maxima**

On level  1  feature { 5 } was removed from current set
Current Set of Features:  []  with accuracy of  75.0 %
---------------------------------------------
Set  [2, 4, 5, 7, 10]  has the highest accuracy: 82.0
Elapsed time: 0.576 seconds

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Welcome to Abhinav's, Majd's, Jacqueline's and Rovin's Feature Selection Algorithms.
Type in the name of the file to test: small-test-dataset.txt
File processed successfully.
Type the number of the algorithm you want to run.
1- Forward Selection.
2- Backward Elimination.
3- Random Combinations.
3

This dataset has 10 features (not including the class attribute), with 100 instances.
Please wait while I normalize the data...

Do you want to Z Normalize the data values? (y/n): Y
Done!

Default number of subsets is  10 and number of features in each set is log( 10 )= 3
Do you want to change the default values? (y/n): n

Num of total features:  10  Features number in one set:  3

Features sets:  [(3, 5, 10), (2, 4, 10), (3, 4, 6), (1, 5, 8), (1, 4, 7), (2, 8, 10), (1, 4, 9), (1, 8, 10), (1, 3, 4), (6, 7, 10)]
---------------------------------------------
Beginning search (Random Feature Combinations).
---------------------------------------------
Accuracy for feature set (3, 5, 10) : 85.0
Accuracy for feature set (2, 4, 10) : 63.0
Accuracy for feature set (3, 4, 6) : 64.0
Accuracy for feature set (1, 5, 8) : 72.0
Accuracy for feature set (1, 4, 7) : 69.0
Accuracy for feature set (2, 8, 10) : 62.0
Accuracy for feature set (1, 4, 9) : 48.0
Accuracy for feature set (1, 8, 10) : 63.0
Accuracy for feature set (1, 3, 4) : 60.0
Accuracy for feature set (6, 7, 10) : 66.0

Set  (3, 5, 10)  has the highest accuracy: 85.0
Elapsed time: 0.071 seconds

Process finished with exit code 0